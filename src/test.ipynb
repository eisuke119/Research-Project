{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DNADataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM\n",
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"PoetschLab/GROVER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_path,\n",
    "        # padding_side=\"right\",\n",
    "        trust_remote_code=True,\n",
    "        # padding=\"max_length\",\n",
    "        padding='max_length', truncation=True, max_length=42\n",
    "    )\n",
    "model = AutoModel.from_pretrained(\n",
    "            model_path, \n",
    "            trust_remote_code=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WITHOUT ATTENTION MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "idx = [1,2,3,4,5]\n",
    "dna_sequences = DNADataset([\"ATCGGCAT\", \"ATCAAAAT\",\"ATCAGCAT\",\"ATCGTTAT\",\"ATCGGTAT\"])\n",
    "batch_size = 5\n",
    "n_gpu=1\n",
    "is_hyenadna = False\n",
    "device = \"cpu\"\n",
    "model = model.to(\"cpu\")\n",
    "first_iteration = None\n",
    "data_loader = DataLoader(\n",
    "    dna_sequences,\n",
    "    batch_size=batch_size * n_gpu,\n",
    "    shuffle=False,\n",
    "    num_workers=1 #2 * n_gpu,\n",
    ")\n",
    "for i, batch in enumerate(tqdm.tqdm(data_loader)):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True)[\n",
    "                \"input_ids\"\n",
    "            ].to(device)\n",
    "        hidden_states = model(inputs)[0]  # index tuple returned by model\n",
    "        embedding = torch.mean(hidden_states, dim=1)  # average \n",
    "        \n",
    "        if i == 0:\n",
    "                embeddings = embedding\n",
    "        else:\n",
    "            embeddings = torch.cat(\n",
    "                (embeddings, embedding), dim=0\n",
    "            )  # concatenate along the batch dimension\n",
    "    embeddings = np.array(embeddings.detach().cpu())\n",
    "\n",
    "    embeddings = embeddings[np.argsort(idx)]\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###WITH ATTENTION MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "idx = [1,2,3,4,5]\n",
    "dna_sequences = DNADataset([\"ATCGGCAT\", \"ATCAAAAT\",\"ATCAGCAT\",\"ATCGTTAT\",\"ATCGGTAT\"])\n",
    "batch_size = 5\n",
    "n_gpu=1\n",
    "is_hyenadna = False\n",
    "device = \"cpu\"\n",
    "model = model.to(\"cpu\")\n",
    "first_iteration = None\n",
    "data_loader = DataLoader(\n",
    "    dna_sequences,\n",
    "    batch_size=batch_size * n_gpu,\n",
    "    shuffle=False,\n",
    "    num_workers=1 #2 * n_gpu,\n",
    ")\n",
    "for i, batch in enumerate(tqdm.tqdm(data_loader)):\n",
    "    with torch.no_grad():\n",
    "        input_tokens = tokenizer.batch_encode_plus(\n",
    "            batch, return_tensors=\"pt\", padding=True\n",
    "        )\n",
    "        input_ids = input_tokens[\"input_ids\"].to(device)\n",
    "        attention_mask = input_tokens['attention_mask'].to(device)\n",
    "        \n",
    "        if is_hyenadna:\n",
    "            model_output = model.forward(input_ids=input_ids)[0].detach().cpu()\n",
    "        else:\n",
    "            model_output = model.forward(input_ids=input_ids, attention_mask=attention_mask)[0].detach().cpu()\n",
    "        \n",
    "        attention_mask = attention_mask.unsqueeze(-1).detach().cpu()\n",
    "        embedding = torch.sum(model_output*attention_mask, dim=1) / torch.sum(attention_mask, dim=1) # along the sequence length\n",
    "        \n",
    "        if i == 0:\n",
    "            embeddings = embedding\n",
    "            first_iteration = np.array(embeddings)\n",
    "        else:\n",
    "            embeddings = torch.cat((embeddings, embedding))\n",
    "embeddings = np.array(embeddings.detach().cpu())\n",
    "embeddings = embeddings[np.argsort(idx)]\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 768])\n",
      "torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "dna = \"TTTTTTTT\"\n",
    "inputs = tokenizer(dna, return_tensors = 'pt')[\"input_ids\"]\n",
    "hidden_states = model(inputs)[0] # [1, sequence_length, 768]\n",
    "print(hidden_states.shape) # expect to be [1, sequence_length, 768]\n",
    "\n",
    "# embedding with mean pooling\n",
    "print(hidden_states[0].shape)\n",
    "embedding_mean = torch.mean(hidden_states[0], dim=0).unsqueeze(0)\n",
    "second_test = np.array(embedding_mean.detach().cpu())[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.28138414 -0.10935557 -0.08664906  0.1703153   0.03078712]\n",
      "[-0.24650352 -0.12896508 -0.11860963  0.1611344   0.0012951 ]\n",
      "0 False\n",
      "0 False\n",
      "[-0.28152242 -0.0984172  -0.08429249  0.16923341  0.01058975]\n",
      "[-0.24650352 -0.12896508 -0.11860963  0.1611344   0.0012951 ]\n",
      "1 False\n",
      "1 False\n",
      "[-0.26513562 -0.04229131 -0.01140821  0.22488098 -0.05971776]\n",
      "[-0.24650352 -0.12896508 -0.11860963  0.1611344   0.0012951 ]\n",
      "2 False\n",
      "2 False\n",
      "[-0.27973628 -0.04341701  0.12714693  0.3036515  -0.24680538]\n",
      "[-0.24650352 -0.12896508 -0.11860963  0.1611344   0.0012951 ]\n",
      "3 False\n",
      "3 False\n",
      "[-0.23722088 -0.03440793  0.05095869  0.22647448 -0.12337677]\n",
      "[-0.24650352 -0.12896508 -0.11860963  0.1611344   0.0012951 ]\n",
      "4 False\n",
      "4 False\n"
     ]
    }
   ],
   "source": [
    "for i in range(embeddings.shape[0]):\n",
    "    embedding_i = embeddings[i]\n",
    "    print(embedding_i[0:5])\n",
    "    print(second_test[0:5])\n",
    "    print(i, np.array_equal(first_iteration,second_test))\n",
    "    print(i, np.allclose(embedding_i, second_test, atol=1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.concatenate([embeddings, embeddings[1:3,:]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 768)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1360"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### GROVER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "  0%|          | 0/1 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "torch.Size([5, 515])\n",
      "torch.Size([5, 515])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (515) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [5, 515].  Tensor sizes: [1, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(attention_mask\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hyenadna:\n\u001b[0;32m---> 27\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/.pyenv/versions/adv_ML/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:979\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    978\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[0;32m--> 979\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (515) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [5, 515].  Tensor sizes: [1, 512]"
     ]
    }
   ],
   "source": [
    "idx = [1,2,3,4,5]\n",
    "dna_sequences = DNADataset([\"ATCGGCAT\"*171, \"ATCAAAAT\"*171,\"ATCAGCAT\"*171,\"ATCGTTAT\"*171,\"ATCGGTAT\"*171])\n",
    "batch_size = 5\n",
    "n_gpu=1\n",
    "is_hyenadna = True\n",
    "device = \"cpu\"\n",
    "model = model.to(\"cpu\")\n",
    "first_iteration = None\n",
    "data_loader = DataLoader(\n",
    "    dna_sequences,\n",
    "    batch_size=batch_size * n_gpu,\n",
    "    shuffle=False,\n",
    "    num_workers=1 #2 * n_gpu,\n",
    ")\n",
    "for i, batch in enumerate(tqdm.tqdm(data_loader)):\n",
    "    with torch.no_grad():\n",
    "        input_tokens = tokenizer.batch_encode_plus(\n",
    "            batch, return_tensors=\"pt\", padding=True, return_attention_mask=True\n",
    "        )\n",
    "        print(input_tokens.keys())\n",
    "        input_ids = input_tokens[\"input_ids\"].to(device)\n",
    "        print(input_ids.shape)\n",
    "        attention_mask = input_tokens['attention_mask'].to(device)\n",
    "        print(attention_mask.shape)\n",
    "        \n",
    "        if is_hyenadna:\n",
    "            model_output = model.forward(input_ids=input_ids)[0].detach().cpu()\n",
    "        else:\n",
    "            model_output = model.forward(input_ids=input_ids, attention_mask=attention_mask)[0].detach().cpu()\n",
    "        print(model_output.shape)\n",
    "        attention_mask = attention_mask.unsqueeze(-1).detach().cpu()\n",
    "        embedding = torch.sum(model_output*attention_mask, dim=1) / torch.sum(attention_mask, dim=1) # along the sequence length\n",
    "        \n",
    "        if i == 0:\n",
    "            embeddings = embedding\n",
    "            first_iteration = np.array(embeddings)\n",
    "        else:\n",
    "            embeddings = torch.cat((embeddings, embedding))\n",
    "embeddings = np.array(embeddings.detach().cpu())\n",
    "embeddings = embeddings[np.argsort(idx)]\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_array(array):\n",
    "    \"Returns array similar to input array but C-contiguous and with own data.\"\n",
    "    if not array.flags[\"C_CONTIGUOUS\"]:\n",
    "        array = np.ascontiguousarray(array)\n",
    "    if not array.flags[\"OWNDATA\"]:\n",
    "        array = array.copy()\n",
    "\n",
    "    assert array.flags[\"C_CONTIGUOUS\"] and array.flags[\"OWNDATA\"]\n",
    "\n",
    "    return array\n",
    "\n",
    "def calculate_vamb_embedding(dna_sequences: list[str], model_path: str) -> np.array:\n",
    "    tnf_embeddings = os.path.join(\"../embeddings\", \"TNF.npy\")\n",
    "\n",
    "    # if os.path.exists(tnf_embeddings):\n",
    "    print(f\"Load TNF-embedding from file {tnf_embeddings}\")\n",
    "    tnf_embeddings = np.load(tnf_embeddings)\n",
    "    # else:\n",
    "    #     tnf_embeddings = calculate_tnf(dna_sequences)\n",
    "\n",
    "    pretrained_vamb_embeddings = np.load(model_path)  # dim (256,100)\n",
    "    kernel = validate_input_array(npz[\"arr_0\"])\n",
    "    print(f\"Load VAMB-embedding from file {model_path}\")\n",
    "    print(f\"shape of VAMB-embedding: {pretrained_vamb_embeddings.shape}\")\n",
    "    # tnf_embeddings += -(1 / 256)\n",
    "    # embeddings = np.dot(tnf_embeddings, pretrained_vamb_embeddings)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load TNF-embedding from file ../embeddings/TNF.npy\n",
      "Load VAMB-embedding from file ../helpers/vamb_embedding.npy\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NpzFile' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcalculate_vamb_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masasd,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../helpers/vamb_embedding.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 12\u001b[0m, in \u001b[0;36mcalculate_vamb_embedding\u001b[0;34m(dna_sequences, model_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m pretrained_vamb_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(model_path)  \u001b[38;5;66;03m# dim (256,100)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad VAMB-embedding from file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape of VAMB-embedding: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_vamb_embeddings\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# tnf_embeddings += -(1 / 256)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# embeddings = np.dot(tnf_embeddings, pretrained_vamb_embeddings)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NpzFile' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "calculate_vamb_embedding([\"asasd,\"], \"../helpers/vamb_embedding.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
